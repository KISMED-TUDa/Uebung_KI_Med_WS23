{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNHRiSWuy_w"
      },
      "source": [
        "# Übung 03 : Stochastische Grundlagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwgeQdww73Ux"
      },
      "source": [
        "Wie üblich importieren wir zuerst unsere Standardbibliotheken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zP-p4bdurd6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B_YFSQ8gB8g"
      },
      "source": [
        "## Aufgabe 1: Korrelation\n",
        "Lade die als *.npy* gespeicherten Bilder *'tower'*, *'hands'*, *'tower_noisy'*.\n",
        "\n",
        "Plotte die Bilder.\n",
        "\n",
        "In der Vorlesung haben wir die Korrelation zweier Signale behandelt. Berechne zur Übung die Korrelationsfunktion (unzentrierte Kovarianz) zwischen *'tower_noisy'* und den anderen Bildern sowie einem Rauschbild mit gleichverteiltem Rauschen auf allen Kanälen. Was stellst du fest? Wie unterscheidet sich die normierte Kovarianz im Ergebnis? Berechne auch diese.\n",
        "\n",
        "*Tipp:* Verwende gerne Standardbibliotheken zur Berechnung (scipy:correlate, openCV:match_template) oder eine eigene Implementierung (naiv implementiert erhöht die Laufzeit drastisch, die Ausgangsbilder sollten die gleiche Dimension wie die Eingänge haben!)\n",
        "\n",
        "*Zusatz:* Nutze die Korrelation zur Berechnung einer einfachen Kantendetektion!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHXRd0UTgCcA"
      },
      "source": [
        "# Laden der Beispiele\n",
        "tower = np.load('tower.npy')\n",
        "tower_noisy = np.load('tower_noisy.npy')\n",
        "hands = np.load('hands.npy')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhA0AaL5gHWE"
      },
      "source": [
        "## Aufgabe 2: Naive Bayes Classifier\n",
        "\n",
        "Reminder: Die Annahme beim Naive Bayes (NB) ist bedingte Unabhängikeit der Merkmale gegeben die Klasse. Der Vorteil, der sich daraus ergibt ist, dass wir nur skalare/univariate Verteilungsdichten schätzen müssen.\n",
        "\n",
        "Ist diese Unabhängigkeit tatsächlich erfüllt?\n",
        "\n",
        "Der Bayes Classifier (non-idiot Bayes) macht diese Annahme nicht. In dieser Übung wollen wir uns anschauen, welche Auswirkungen das auf das Klassifikationsergebnis hat.\n",
        "\n",
        "Gegeben ist ein Datensatz aus zwei korrelierten Merkmalen und den zugehörigen Klassen (Datensatz b). Außerdem gibt es einen Datensatz a mit zwei unkorrelierten Merkmalen.\n",
        "Vergleiche durch Plots und Berechnung der Klassifikationsergebnisse für Testdaten die beiden Klassifier (NB und non-idiot Bayes). Ihr dürft annehmen, dass die Merkmale einer Gaussverteilung folgen.\n",
        "\n",
        "*Zusatz:* Reduziere die Menge der Trainingsdaten, wie verhalten sich die beiden Classifier? Erstelle eigene Trainingsdaten mit größerer Feature-Anzahl, was beobachtest du?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK29ZbmJBBSh"
      },
      "source": [
        "# Lade und plotte die Daten\n",
        "# Wir haben zwei Datensätze (a und b) aus unterschiedlichen Verteilungen, in denen jeweils zwei Klassen exisitieren\n",
        "\n",
        "with np.load('data_bayes_clas.npz') as data:\n",
        "  class1_a = data['class1_a']\n",
        "  class2_a = data['class2_a']\n",
        "  class1_a_test = data['class1_a_test'] # Unser Testdatum, von dem wir wissen, dass es zu Klasse 1 gehört\n",
        "  class1_b = data['class1_b']\n",
        "  class2_b = data['class2_b']\n",
        "  class1_b_test = data['class1_b_test'] # Unser Testdatum, von dem wir wissen, dass es zu Klasse 1 gehört\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kaX0KpggHAf"
      },
      "source": [
        "# Programmiere die Classifier und Löse die Aufgabe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgSTYnqIu_uf"
      },
      "source": [
        "## Aufgabe 3: Zentraler Grenzwertsatz\n",
        "\n",
        "Die Wahrscheinlichkeit im Laufe des Lebens an Lungenkrebs zu erkranken beträgt für Frauen in den USA 6%. Pro Tag werden etwa 5000 weibliche Babys auf die Welt gebracht. Wie sieht die Wahrscheinlichkeitsverteilung aus, wenn wir betrachten wollen, wieviele der  am heutigen Tag geborenen Frauen im Laufe ihres Lebens an Lungenkrebs erkranken werden?\n",
        "\n",
        "\n",
        "a) Simuliere die Häufigkeit, wobei du jede Person berücksichtigst. Plotte das Histogramm.\n",
        "\n",
        "b) Was sagt der Zentrale Grenzwertsatz aus? Können wir das Ergebnis durch eine parametrierte Funktion annähern? Wie lassen sich die Parameter berechnen?\n",
        "\n",
        "Quelle https://de.statista.com/statistik/daten/studie/457384/umfrage/usa-wahrscheinlichkeit-der-entwicklung-von-lungenkrebs/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTK90qNMu_W_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mQlUOuAbcyu4",
        "e5qP03NRc-Ev"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQlUOuAbcyu4"
      },
      "source": [
        "# 1. Metriken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xGWKASOc9iw"
      },
      "source": [
        "**a)** Führe die folgende Zelle aus, um eine Confusion Matrix zu erhatlten. Bestimme daraus die Prävalenz, den Bias, die Sensitivität und Spezifität, sowie Precision und Recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is3Z1T1xPaSI",
        "cellView": "form"
      },
      "source": [
        "#@markdown Der Code ist hier nicht weiter interessant, ihr braucht die Zelle einfach nur auszuführen.\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "rd.seed(0)\n",
        "\n",
        "fraction_negatives = 0.42\n",
        "gesamtmenge = 200\n",
        "\n",
        "y_true=np.concatenate((np.ones((1,int(gesamtmenge*(1-fraction_negatives)))),np.zeros((1,int(gesamtmenge*fraction_negatives)))),1).T\n",
        "positive_pred_distribution = np.array([min(1,rd.gauss(0.75,0.25)) for i in range(0,int(gesamtmenge*(1-fraction_negatives)))])\n",
        "negative_pred_distribution = np.array([max(0,rd.gauss(0.33,0.2)) for i in range(0,int(gesamtmenge*fraction_negatives))])\n",
        "predictions = np.concatenate((positive_pred_distribution,negative_pred_distribution),0)\n",
        "y_hat = predictions >= 0.66\n",
        "conf_mat = pd.DataFrame(confusion_matrix(y_true,y_hat), index=[\"negativ\",\"positiv\"],columns=[\"'negativ' klassifiziert\", \"'positiv' klassifiziert\"])\n",
        "conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZU3OHGJksN3"
      },
      "source": [
        "**b)** Angenommen, ein Klassifikator hat eine Sensitivität von $0.86$, eine Spezifität von $0.85$ und einen F1-Score von $0.12$. Wie groß ist die Prävalenz $p$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE5Wqc2Qedfl"
      },
      "source": [
        "Führe die nächste Zelle aus. Der Code ist absichtlich ausgeblendet, da ihr ihn für diese Übung nicht zu verstehen braucht. Die Zelle erstellt einen Plot, den man interaktiv über einen Schieberegler verändern kann. Der Plot visualisiert das letzte Layer eines Neuronalen Netzes, das eine Klassifikation vornimmt. Das Layer besteht aus einer Sigmoid-Funktion, die die Inputs (repräsentiert durch die senkrechten Striche) in Wahrscheinlichkeiten, also Werte zwischen 0 und 1 umrechnet. Die Farbe der Striche codiert, ob es sich um einen positiven (gelb) oder einen negativen (blau) Wert handelt. Der grüne, wagrechte Strich repräsentiert die Grenze $\\alpha$, ab der Werte als positiv klassifiziert werden. Über den Schieberegler kann man $\\alpha$ zwischen 0.01 und 0.99 verschieben. \n",
        "\n",
        "**c)** Nutze diese Möglichkeit, $\\alpha$ verändern zu können, um das optimale $\\alpha$ zu schätzen. Skizziere dann per Hand eine PRC- und eine ROC-Kurve. Überlege Dir dafür auch, was in den Grenzfällen $\\alpha=0$ und $\\alpha=1$ passiert. Gib dann eine zweite Schätzung für den optimalen Wert von $\\alpha$, basierend auf deiner Skizze, an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yUR-Co8e2kG",
        "cellView": "form"
      },
      "source": [
        "#@markdown Ihr müsst diese Zelle nur ausführen, der Code ist nicht weiter interessant\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "\n",
        "random.seed(0)\n",
        "pal = sns.color_palette(\"colorblind\")\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def inv_sigmoid(x):\n",
        "  return np.log(x/(1-x))\n",
        "\n",
        "x = np.linspace(-10, 10, num=1601)\n",
        "f1 = sigmoid(x)\n",
        "\n",
        "def update(alpha):\n",
        "  plt.figure(figsize=(24,12))\n",
        "  plt.plot(x,f1,lw=2)\n",
        "  plt.hlines(alpha, -10, np.log(alpha/(1-alpha)),colors=pal[2],lw=3)\n",
        "  tp = 10**(-6)\n",
        "  fp = 10**(-6)\n",
        "  fn = 10**(-6)\n",
        "  tn = 10**(-6)\n",
        "  for p,y in zip(predictions,y_true):\n",
        "    if y==0:    \n",
        "      if p < alpha:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[0],alpha=0.2)\n",
        "        tn += 1\n",
        "      else:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[0])\n",
        "        fp += 1\n",
        "    else: \n",
        "      if p >= alpha:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[1])\n",
        "        tp += 1\n",
        "      else:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[1],alpha=0.2)\n",
        "        fn += 1\n",
        "  tex = 'TPR: ' + str(int(1000*(tp+10**(-6))/(tp+fn+10**(-6)))/1000) + '\\nFPR: ' + str(int(1000*(fp+10**(-6))/(fp+tn+10**(-6)))/1000) + '\\nPrecision: ' + str(int(1000*(tp+10**(-6))/(tp+fp+10**(-6)))/1000) + '\\nRecall: ' + str(int(1000*(tp+10**(-6))/(tp+fn+10**(-6)))/1000)\n",
        "  if alpha > 0.8:\n",
        "    tex_y = 0.6\n",
        "  else:\n",
        "    tex_y = 0.8\n",
        "  plt.text(-8,tex_y,tex,fontsize=20)\n",
        "\n",
        "interact(update, alpha = widgets.FloatSlider(value=0.5,min=0.005, max=0.995, step = 0.01,layout=Layout(width='1000px')))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5qP03NRc-Ev"
      },
      "source": [
        "# 2. Validierungsverfahren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrtfvJPWRfgS"
      },
      "source": [
        "**a)** Führe die folgende Zelle aus, um die beiden Datensätze *data_for_training.csv* und *data_for_testing.csv* zu importieren. Bei den Daten handelt es sich um einen zufälligen Split eines Datensatzes für [Weinqualität](https://www.kaggle.com/vishalkumbhar1997/wine-quality-prediction-with-logistic-regression). Die Aufgabe besteht darin, einen Klassifikator zu erstellen, der aus den Features die Qualität (`quality`) richtig erkennt. Die Qualität ist dabei für diese Aufgabe binär in gut (1) und schlecht (0) codiert. Führe dann die nächste Zelle aus. Diese erstellt mit der Bibliothek `sklearn` einen Entscheidungsbaum (Der ist das Thema der nächsten Vorlesung, die genaue Funktionsweise ist für diese Übung nicht wichtig), trainiert ihn auf dem Datensatz *data_for_training.csv* und testet ihn dann auf dem Datensatz *data_for_testing.csv*. Wie ihr seht, ist der Score (hier wird standardmäßig die Accuracy berechnet) auf dem zweiten Datensatz deutlich niedriger. Hier liegt also Overfitting vor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCPlynEpdGwY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_wines = pd.read_csv('/content/gdrive/MyDrive/data_for_training.csv')\n",
        "test_wines = pd.read_csv('/content/gdrive/MyDrive/data_for_testing.csv')\n",
        "\n",
        "train_wines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us5cJoDYi2hB"
      },
      "source": [
        "y = train_wines['quality']\n",
        "X = train_wines.drop('quality',axis=1)\n",
        "\n",
        "y_test = test_wines['quality']\n",
        "X_test = test_wines.drop('quality',axis=1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier().fit(X,y)\n",
        "\n",
        "# training und validation accuracy\n",
        "print(\"Tree with depth \" + str(tree.get_depth()) + \"; train score: \"+str(tree.score(X,y)) + \"; val score: \"+str(tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIa3rofTe2CS"
      },
      "source": [
        "**b)** Teile den Datensatz *data_for_training.csv* in einen Trainings- und einen Validierungsdatensatz auf. Der Datensatz *data_for_testing.csv* wird fürs erste nicht weiter beachtet. Nutze die in der Vorlesung vorgestellten Mehtoden der Validierung und Kreuzvalidierung um Hyperparameterkonfigurationen zu finden, die weniger overfitten als die Standardkonfiguration. \n",
        "\n",
        "**Hinweis:** Der Entscheidungsbaum hat verschiedene Hyperparamter, unter anderem die maximale Baumtiefe (`max_depth`) und das Teilungskriterium (`criterion`). Man kann zum Beispiel auch spezifizieren, wie viele Parameter bei jeder Teilung berücksichtigt werden sollen (`max_features`). Die Erklärung aller Parameter kann [hier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) nachgelesen werden. Ihr könnt euch bei dieser Aufgabe aber auch auf einen Parameter (z.B. `max_depth`) konzentrieren und für den einen optimalen Wert finden.\n",
        "\n",
        "**Hinweis2:** Die Bibliothek `sklearn` liefert viele Optionen zur Hyperparameteroptimierung und Validierung. Bei Interesse findet ihr [hier](https://scikit-learn.org/stable/modules/cross_validation.html) und [hier](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) weitere Infos. Die Klasse `sklearn.model_selection.cross_val_score` bietet z.B. die Möglichkeit, unterschiedliche und sogar eigene Gütekriterien bei der Kreuzvalidierung zu berechen. Hier kann man einfach ein bisschen ausprobieren!\n",
        "\n",
        "**c)** Teste deinen fertigen Klassifikator auf dem bei b) nicht berücksichtigten Datensatz *data_for_testing.csv*. Wie gut ist dein Ergebnis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLDWSy4ndnL6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uebung11_XAI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lb6J13iBmID2",
        "1tK-43xCqB_Y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Explainable AI\n",
        "\n",
        "Da wir in der Vorlesung inzwischen bei anwendungsbezogeneren Themen angekommen sind, wollen wir die verbliebenen Übungen nutzen, um Euch etwas freier an Aufgabenstellungen arbeiten zu lassen. Die Konzepte der Vorlesungen sollend abei als Grundgedanken bei der Auswahl und Implementierung der Algorithmen einfließen. Heute werden wir uns mit explainable AI, oder kurz XAI, beschäftigen.\n",
        "\n",
        "**Zentral wird es bei dieser Übung darum gehen, dass Ihr einen Klassifikator implementiert, der entscheidet, ob eine Person an einer [koronaren Herzkrankheit](https://de.wikipedia.org/wiki/Koronare_Herzkrankheit) leidet. Nachdem der eigentliche Klassifikator implementiert wurde, wollen wir in der zweiten Aufgabe mithilfe von Methoden der XAI eine Theorie untersuchen, laut der die Persönlichkeit eines Menschen Einfluss hat auf die Wahrscheinlichkeit, an einer solchen Krankheit zu erkranken. Näheres zu dieser Theorie über Persönlichkeitstypen und ihren Einfluss auf Herzerkrankungen können Sie [hier](https://en.wikipedia.org/wiki/Type_A_and_Type_B_personality_theory) nachlesen.**\n",
        "\n",
        "Wir importieren zunächst den gegebenen Datensatz `CHDdata.csv` ([Quelle](https://www.kaggle.com/billbasener/coronary-heart-disease)) und machen unsere Standard-Imports. Die Labels der Spalten stehen für:\n",
        "\n",
        "*   Systolischer Blutdruck (systolic blood pressure, `sbp`)\n",
        "*   Jährlicher Tabakkonsum in kg (`tobacco`)\n",
        "*   Anteil an Lipoproteinen niedriger Dichte, ähnlich Cholesterinspiegel (low density lipoprotein ,`Idl`)\n",
        "*   Body Adiposity Index, Maß für Körperfettanteil (`adiposity`)\n",
        "*   Type A Personality Score; codiert von 0 bis 100, wobei ein höherer Score bedeutet, dass die Person eher Persönlichkeitstyp A hat. (`typea`)\n",
        "*   Familienhistorie (`famhist`, kodiert als vorhanden, also \"Present\" oder nicht vorhanden also \"Absent\")\n",
        "*   Body Mass Index (`obesity`)\n",
        "*   Alkoholkonsum pro Jahr in Litern reinen Alkohols (`alcohol`)\n",
        "*   Alter in Jahren (`age`)\n",
        "*   Diagnose einer koronaren Herzkrankheit; Zielgröße unseres Klassifikators (coronary heart disease, `chd`, 0 für nein, 1 für ja)"
      ],
      "metadata": {
        "id": "A_fIBjtwLXZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "PjbuHuiNQzTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdkBE-REv_RP"
      },
      "outputs": [],
      "source": [
        "# Wie üblich\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# importieren der Daten\n",
        "chd = pd.read_csv('/content/gdrive/MyDrive/CHDdata.csv')\n",
        "chd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Freies Lösen eines Klassifikationsproblems\n",
        "\n",
        "Die erste Aufgabe besteht nun darin, selbstständig ein funktionierendes Modell zu finden, dass die Zielgröße `chd` aus den Features vorhersagt. Die Aufgabenstellungen sind dabei allgemeiner gehalten als bei bisherigen Übungen und eher als Anhaltspunkte zu verstehen. Ihr sollt das Problem mehr oder weniger selbstständig bearbeiten und seid in der Implementierung daher völlig frei. \n",
        "\n",
        "Zuerst solltet ihr euch um die Vorverarbeitung der Daten kümmern.\n",
        "\n",
        "a)   Bereinige den Datensatz von leeren Zellen und transformiere kategorische Features in Zahlen.\n",
        "\n",
        "b)   Teile die existierende Tabelle in Zielgröße und Features auf, erstelle außerdem getrennte Teildatensätze für Training, Validation und Test. \n",
        "\n",
        "c)   Inspiziere die Daten, um erste Erkenntnisse zu gewinnen und fundierte Ansätze bezüglich der Modelle wählen zu können. Verschiedene Ansätze zur Inspektion können z.B. das Anschauen von Metadaten (also max, min, Anzahl pro Feature etc.), die Korrelation oder auch einfach das Plotten von Features, sein. Überlege dir, welche Features vermutlich relevant und welche womöglich redundant sind. Bedenke, dass es auch sinnvoll sein kann, an den Features etwas zu ändern (also Feature Engineering zu betreiben).\n",
        "\n",
        "d) Normalisiere die Daten."
      ],
      "metadata": {
        "id": "lb6J13iBmID2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEIN CODE\n"
      ],
      "metadata": {
        "id": "JoRWwLP_nDXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nach der Datenanalyse kannst Du jetzt die eigentlichen Klassifikationsmodelle bauen:\n",
        "\n",
        "e)   Entscheide dich zunächst für Evaluierungsmaße, mit denen Du Deine Modelle bewerten willst. Falls Du eine Auffrischung brauchst, welche Kriterien wir dafür zur Auswahl haben, kannst Du nochmal in VL und Übung 06 reinschauen. Warum ist es sinnvoll, mit diesem Schritt anzufangen?\n",
        "\n",
        "f)   Wähle mindestens 3 Modelle aus, mit denen Du das Problem angehen willst. Zur Erinnerung: Wir haben in den bisherigen Übungen und Vorlesungen bereits folgende für Klassifikation geeignete Modelle kennen gelernt: \n",
        "\n",
        "\n",
        "*   Naive Bayes Classifier (Übung 03)\n",
        "*   Logistische Regression (VL 04)\n",
        "*   k-Nearest-Neighbor Classifier (Übung 05)\n",
        "*   Entscheidungsbäume und Random Forest, XGBoost (Übung 07)\n",
        "*   Neuronale Netze (Übungen 08 und 09)\n",
        "\n",
        "**Tipp:** Je nachdem, wie ausführlich Deine Datenvorverarbeitung war, bieten sich unterschiedliche Modelle an. Ein neuronales Netz braucht z.B. deutlich weniger Vorverarbeitung als eine logistische Regression; für einen kNN Klassifikator kann wiederum eine PCA sinnvoll sein etc.\n",
        "\n",
        "g)   Implementiere und trainiere Deine Modelle. Du kannst hier gerne eine Implementierung aus den vorherigen Übungen übernehmen oder existierende Bibliotheken zur vereinfachten Implementierung verwenden. \n",
        "\n",
        "h)   Verbessere Dein Modell, indem Du Anpassungen vornimmst. Nutze dafür Verfahren wie Regularisierung (Übung 04) und Hyperparametertuning (Übung 06). Die Optimierung eines Decision-Trees wird außerdem in Übung 07 ausführlich behandelt.\n",
        "\n",
        "i)   Berechne Deine Evaluierungsmaße auf dem Test Set. Hattest du diese Ergebnisse erwartet?"
      ],
      "metadata": {
        "id": "fKmVsW7Ncorg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEIN CODE\n"
      ],
      "metadata": {
        "id": "c8ZwzaTxZjFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. XAI\n",
        "\n",
        "In dieser Aufgabe sollt Ihr Eure Modelle auf Interpretability untersuchen. Wie aus der Vorlesung bekannt, gilt:\n",
        "\n",
        "*Interpretability = Transparency + Explainability*\n",
        "\n",
        "a) Zunächst wollen wir uns mit der Transparency beschäftigen. Sortiere Deine Modelle absteigend danach, wie intrinsisch transparent sie sind.\n",
        "\n",
        "Als nächstes wollen wir die in der Vorlesung gezeigten Algorithmen LIME und SHAP verwenden. Daüf müssen wir zunächst einmal die entsprechenden Bibliotheken installieren und dann importieren. Die Dokumentation von LIME findet Ihr [hier](https://lime-ml.readthedocs.io/en/latest/lime.html#) und die von SHAP [hier](https://shap-lrjball.readthedocs.io/en/docs_update/api.html#)."
      ],
      "metadata": {
        "id": "1tK-43xCqB_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Führe diese Zelle aus, um die LIME und SHAP Bilbiotheken zu installieren\n",
        "!pip install lime\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "dzwDnODVmcKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Jetzt wo die Bibliotheken installiert sind, wollen wir sie auch verwenden. Erstelle ein `LimeTabularExplainer` Objekt und übergib ihm die Parameter `training_data`, `feature_names` und `class_names`, um es zu initialisieren. Verwende dann die Funktion `explain_instance`, um dir für **einen** Datenpunkt eine Erklärung der Klassifikation ausgeben zu lassen. \n",
        "\n",
        "**Achtung:** `explain_instance` erwartet als Parameter eine `predict_fn`, die Wahrscheinlichkeiten für alle Klassen zurück gibt und nicht etwa ein Klassenlabel. Modelle, die auf der `sklearn` Bibliothek beruhen, haben dafür die Funktion `predict_proba`. Bei anderen Modellen ist das jedoch etwas komplizierter. Deshalb stellen wir Euch die Hilfsfunktion `predict_proba_keras` zur Verfügung, die diese Funktionalität für mit Keras erstellte neuronale Netze bereitstellt. Da die Funktion aber nur einen Parameter, nämlich die Daten, haben darf, müsst ihr noch den Namen des Modells auf euer Modell anpassen.\n",
        "\n",
        "Wende den Explainer auf alle Deine Modelle an und lass dir jeweils das Ergebnis mit der Funktion `show_in_notebook` anzeigen. Probiere unterschiedliche Datenpunkte aus und versuche interessante Beobachtungen zu finden. **Stützen Deine Beobachtungen die These, dass der Personality Type A eine erhöhte Gefahr bedingt, an einer koronaren Herzkrankheit zu erkranken?**"
      ],
      "metadata": {
        "id": "E6Uo0uS3yUxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime import lime_tabular\n",
        "\n",
        "class_labels = ['no_chd','chd']\n",
        "feature_labels = X_test.columns\n",
        "\n",
        "# DEIN CODE"
      ],
      "metadata": {
        "id": "oD8NC5L-nI2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Wiederhole Aufgabentyp b) für den SHAP Algorithmus. Falls Du Modelle mit baumartiger Struktur (also Decision Trees, Random Forests,...) verwendest, kannst du dafür den `TreeExplainer` verwenden, ansonsten den langsameren `KernelExplainer`. Erster braucht nur das Modell als Eingabewert, zweiter braucht eine Predict-Function genau wie der `lime_explainer`, sowie einen Datensatz. Auf Ihrem Explainer können Sie mit `shap_values` die Shapley-Werte berechnen. Dies geht entweder auf einem einzelnen Datenpunkt, um anschließend einen `force_plot` zu erstellen, oder auf einer Menge von Punkten (bzw. dem ganzen Datensatz), um einen `summary_plot` zu erstellen.\n",
        "\n"
      ],
      "metadata": {
        "id": "tWNdbu9Jxe3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "shap.initjs() # dieser Befehl initialisiert eine Javascript-Umgebung und ist in jeder Zelle, die Shap-Plots erstellen soll, nötig!\n",
        "\n",
        "# DEIN CODE"
      ],
      "metadata": {
        "id": "JsjrDydWSz6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Ist eine abschließende Aussage zur Interpretierbarkeit Deiner Modelle möglich? Welche Erkenntnisse konntest du gewinnen?"
      ],
      "metadata": {
        "id": "eBacn0vV0vBd"
      }
    }
  ]
}